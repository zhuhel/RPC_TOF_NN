{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V0830_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOygYRa8V9Z/7RrruVaeRJ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhuhel/RPC_TOF_NN/blob/main/V0830_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrdHsuKYIwJY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a6316190-e955-484b-f8a1-14d821cdbf0c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrpiDy0LIgVQ"
      },
      "source": [
        "########################################################################################\n",
        "## PACKAGE IMPORTING AND GLOBAL VARIABLE DEFINITION ########\n",
        "########################################################################################\n",
        "\n",
        "# from 721, set bias=False for LSTM and MLP; LSMT layer =1 and no dropout # one layer LSTM may be enough\n",
        "# V0.7  Update: Use large hidden size; MSE as loss function; Based on V0.60\n",
        "# V0.6  Update: Type 3 has better performance than type 4\n",
        "# V0.51 Update: to run on the oscilloscope data\n",
        "# V0.40 Update: to come different networks\n",
        "# V0.31 Update: tof changed to tensor format, which is a grammar improvement instead of bug fix\n",
        "# V0.32 Update: Use L2 regularization instead of drapout\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch    # for setting seed to make it reproducible\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt  # for plotting\n",
        "import matplotlib.mlab as mlab  # for plotting\n",
        "import struct  # for binary file reading\n",
        "import numpy as np\n",
        "import time  # for time recording\n",
        "import math  # for sqrt\n",
        "from pathlib import Path  # for the size of the binary file\n",
        "from scipy.stats import norm  # for gaussian fit\n",
        "import sys  # for parameter receiving\n",
        "import os  # for mkdir\n",
        "from progressbar import *\n",
        "\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
        "time_start = time.time()\n",
        "time_epoch = time.time()\n",
        "\n",
        "SEED=5  # reproducible\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(SEED)\n",
        "SAMPLE_EPOCH = 1  # test every xx epochs to record mu, timeresolution, and loss\n",
        "EPOCHS = 100\n",
        "\n",
        "MODEL_VERSION = '830'\n",
        "DATA_VERSION = 'Aug-200_900_6'\n",
        "WAVE_LENGTH = 160\n",
        "NCHANNEL = 2\n",
        "\n",
        "LR = 0.0001 + 0.0009*np.random.rand()\n",
        "LRD = 0.9 + 0.1*np.random.rand()\n",
        "HIDDEN_SIZE = 60 + int(10*np.random.rand())\n",
        "NUM_LSTM_LAYERS = 4 #+int(2*np.random.rand())\n",
        "BATCH_SIZE = 256\n",
        "DROP_OUT = 0.0\n",
        "WEIGHT_DECAY = 0.0004 + 0.0004*np.random.rand()  # lambda of L2 regularization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAmG77Z7JHEc"
      },
      "source": [
        "########################################################################################\n",
        "## CLASS AND FUNCTIION DEFINITION ########\n",
        "########################################################################################\n",
        "\n",
        "class Waveforms(Dataset):\n",
        "    def __init__(self, root_dir, testRate = 0.3, train=True):\n",
        "        self.root_dir = root_dir\n",
        "        self.train = train\n",
        "        self.file = open(root_dir, 'rb')\n",
        "        self.waveLength = WAVE_LENGTH\n",
        "        self.NChannel = NCHANNEL\n",
        "        self.NEvents = Path(self.root_dir).stat().st_size / \\\n",
        "            (self.waveLength*self.NChannel+1)/4\n",
        "        print('NEvents = ', self.NEvents)\n",
        "        self.testRaio = testRate\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return int(self.NEvents*(1.0-self.testRaio))\n",
        "        else:\n",
        "            return int(self.NEvents*self.testRaio)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            self.file.seek((index+int(self.NEvents*self.testRaio))\n",
        "                           * (self.NChannel*self.waveLength+1)*4, 0)\n",
        "        else:\n",
        "            self.file.seek((index)*(self.NChannel*self.waveLength+1)*4, 0)\n",
        "        data = self.file.read(self.waveLength*self.NChannel*4)\n",
        "        wave = struct.unpack(str(self.NChannel*self.waveLength)+'f', data)\n",
        "        wave_tensor = torch.tensor(wave, dtype=torch.float32).reshape(\n",
        "            self.NChannel, self.waveLength)\n",
        "        data = self.file.read(4)\n",
        "        tof = struct.unpack('f', data)\n",
        "        tof_tensor = torch.tensor(tof, dtype=torch.float32)\n",
        "        sample = {'waveform': wave_tensor, 'tof': tof_tensor}\n",
        "        return sample\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, common_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(input_size, input_size // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(input_size // 2, input_size // 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(input_size // 4, common_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "class ComNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=WAVE_LENGTH,\n",
        "            hidden_size=HIDDEN_SIZE,\n",
        "            num_layers=NUM_LSTM_LAYERS,\n",
        "            batch_first=True,\n",
        "            bias=False,\n",
        "            dropout=DROP_OUT\n",
        "        )\n",
        "        self.out1 = nn.Linear(HIDDEN_SIZE, 1, bias=False)\n",
        "        # self.magnifier1 = MLP(NCHANNEL*WAVE_LENGTH, WAVE_LENGTH) # N to one\n",
        "        # self.magnifier2 = MLP(NCHANNEL*WAVE_LENGTH, WAVE_LENGTH) # N to one\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.dim\n",
        "        # # print('x:\\t', x.size())\n",
        "        # extra1 = self.magnifier1(x.view(x.size(0),NCHANNEL*WAVE_LENGTH))\n",
        "        # extra1 = extra1.unsqueeze(2)\n",
        "        # extra2 = self.magnifier2(x.view(x.size(0),NCHANNEL*WAVE_LENGTH))\n",
        "        # extra2 = extra2.unsqueeze(2)\n",
        "        # # print('extra:\\t', extra.size())\n",
        "        # x = torch.cat((x,extra1), 2)\n",
        "        # x = torch.cat((x,extra2), 2)\n",
        "        # print('cat:\\t', x.size())\n",
        "\n",
        "        lstm_out, (h_n, h_c) = self.lstm(x, None)\n",
        "        # lstm_out[:, -1, :] is the last lines of the input batches, since it's a many to one IO structure.\n",
        "        out = (self.out1(lstm_out[:, -1, :]))\n",
        "        return out\n",
        "\n",
        "\n",
        "def testDataset(network, dataVersion, outputPrefix, input_prefix = \"./Codes/V0.70/Data/\"):\n",
        "    inputFileName = input_prefix+dataVersion+\".bin\"\n",
        "    testWaveformDataset = Waveforms(inputFileName, testRate = 1.0, train=False)\n",
        "    testData = DataLoader(testWaveformDataset,\n",
        "                          batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    residualTofList = []\n",
        "    predictedTofList = []\n",
        "    labelTofList = []\n",
        "    print(\"Test Data: \" + dataVersion)\n",
        "    mu=sigma=0\n",
        "    with torch.no_grad( ):\n",
        "        for index, batch_data in enumerate(testData):\n",
        "            input = Variable(batch_data['waveform']).cuda()\n",
        "            b_y = Variable(batch_data['tof']).cuda().squeeze()\n",
        "            output = comNN(input).squeeze()\n",
        "            residualTofList.extend(\n",
        "                (output-b_y).cpu().detach().numpy().tolist())\n",
        "            predictedTofList.extend(output.cpu().detach().numpy().tolist())\n",
        "            labelTofList.extend(b_y.cpu().detach().numpy().tolist())\n",
        "\n",
        "    (mu, sigma) = norm.fit(residualTofList)\n",
        "    n, bins, patches = plt.hist(residualTofList, 50, range=(-2, 2), density=1)\n",
        "    # add a 'best fit' line\n",
        "    y = norm.pdf(bins, mu, sigma)\n",
        "    l = plt.plot(bins, y, 'r--', linewidth=2)\n",
        "    plt.xlabel('Tof residual [ns]')\n",
        "    plt.title(\n",
        "        r'$\\mathrm{Tof\\ residual:}\\ \\mu=%.3f ns,\\ \\sigma/\\sqrt{2}=%.3f ns$' % (mu, sigma/math.sqrt(2)))\n",
        "    plt.grid(True)\n",
        "    plt.savefig(outputPath + outputPrefix +\n",
        "                \"Test_\" + dataVersion + \".png\")\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "def my_mse_loss(x, y, n): \n",
        "    return torch.mean(torch.pow(torch.abs(x - y), n))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOuQ7yc7JYB0"
      },
      "source": [
        "########################################################################################\n",
        "## INPUT/OUTPUT PATH SETTING ########\n",
        "########################################################################################\n",
        "\n",
        "workspace = '/content/gdrive/My Drive/RPC_TOF/'\n",
        "fileName = workspace+\"/data/\"+DATA_VERSION+\".bin\"\n",
        "outputPath = workspace+DATA_VERSION+\"_\"+MODEL_VERSION+\"_Aug20th_v1/\"\n",
        "if os.path.exists(outputPath) == False:\n",
        "    os.mkdir(outputPath)\n",
        "outputPrefix = DATA_VERSION+\"_SEED\"+str(SEED).zfill(4) + \"_E\"+str(EPOCHS)\n",
        "\n",
        "if False:\n",
        "  print('workspace:',workspace,os.path.exists(workspace))\n",
        "  print('fileName:',fileName,os.path.exists(fileName))\n",
        "  print('outputPath:',outputPath,os.path.exists(outputPath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX070NRyr3GY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb694606-404d-48fe-a9ab-97b0f1bf3b19"
      },
      "source": [
        "!ls /content/gdrive/'My Drive'/RPC_TOF/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aug-200_900_6_830_Aug20th_v1  data    Shift-200_900_6_830_Aug20th_v1\n",
            "Code\t\t\t      data_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB8NQAD9KCY0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0183cd5-d539-426d-bf6a-43d7a5d48aef"
      },
      "source": [
        "test_form = Waveforms(fileName, train=True)\n",
        "test_Data = DataLoader(test_form, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print(test_form[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEvents =  7815.0\n",
            "{'waveform': tensor([[ 6.6270e-01,  6.3900e-01,  5.9449e-01,  5.3345e-01,  4.6099e-01,\n",
            "          3.8262e-01,  3.0384e-01,  2.2978e-01,  1.6479e-01,  1.1225e-01,\n",
            "          7.4304e-02,  5.1869e-02,  4.4597e-02,  5.1012e-02,  6.8694e-02,\n",
            "          9.4530e-02,  1.2499e-01,  1.5641e-01,  1.8528e-01,  2.0846e-01,\n",
            "          2.2336e-01,  2.2811e-01,  2.2158e-01,  2.0338e-01,  1.7386e-01,\n",
            "          1.3396e-01,  8.5143e-02,  2.9230e-02, -3.1701e-02, -9.5442e-02,\n",
            "         -1.5975e-01, -2.2241e-01, -2.8129e-01, -3.3439e-01, -3.7982e-01,\n",
            "         -4.1588e-01, -4.4101e-01, -4.5389e-01, -4.5345e-01, -4.3891e-01,\n",
            "         -4.0993e-01, -3.6659e-01, -3.0951e-01, -2.3985e-01, -1.5936e-01,\n",
            "         -7.0238e-02,  2.4890e-02,  1.2322e-01,  2.2197e-01,  3.1869e-01,\n",
            "          4.1162e-01,  4.9996e-01,  5.8429e-01,  6.6675e-01,  7.5132e-01,\n",
            "          8.4383e-01,  9.5196e-01,  1.0850e+00,  1.2535e+00,  1.4688e+00,\n",
            "          1.7422e+00,  2.0845e+00,  2.5050e+00,  3.0108e+00,  3.6057e+00,\n",
            "          4.2903e+00,  5.0608e+00,  5.9089e+00,  6.8222e+00,  7.7839e+00,\n",
            "          8.7735e+00,  9.7676e+00,  1.0741e+01,  1.1667e+01,  1.2519e+01,\n",
            "          1.3274e+01,  1.3909e+01,  1.4407e+01,  1.4754e+01,  1.4942e+01,\n",
            "          1.4968e+01,  1.4835e+01,  1.4552e+01,  1.4131e+01,  1.3589e+01,\n",
            "          1.2946e+01,  1.2223e+01,  1.1443e+01,  1.0628e+01,  9.7969e+00,\n",
            "          8.9691e+00,  8.1594e+00,  7.3802e+00,  6.6401e+00,  5.9447e+00,\n",
            "          5.2967e+00,  4.6963e+00,  4.1422e+00,  3.6315e+00,  3.1612e+00,\n",
            "          2.7280e+00,  2.3294e+00,  1.9635e+00,  1.6295e+00,  1.3273e+00,\n",
            "          1.0577e+00,  8.2191e-01,  6.2101e-01,  4.5580e-01,  3.2623e-01,\n",
            "          2.3112e-01,  1.6789e-01,  1.3251e-01,  1.1955e-01,  1.2240e-01,\n",
            "          1.3366e-01,  1.4559e-01,  1.5070e-01,  1.4228e-01,  1.1501e-01,\n",
            "          6.5375e-02, -7.9894e-03, -1.0411e-01, -2.1969e-01, -3.4934e-01,\n",
            "         -4.8594e-01, -6.2115e-01, -7.4615e-01, -8.5226e-01, -9.3168e-01,\n",
            "         -9.7819e-01, -9.8761e-01, -9.5827e-01, -8.9114e-01, -7.8980e-01,\n",
            "         -6.6025e-01, -5.1047e-01, -3.4977e-01, -1.8816e-01, -3.5557e-02,\n",
            "          9.8986e-02,  2.0794e-01,  2.8585e-01,  3.2979e-01,  3.3945e-01,\n",
            "          3.1720e-01,  2.6777e-01,  1.9788e-01,  1.1558e-01,  2.9620e-02,\n",
            "         -5.1340e-02, -1.1943e-01, -1.6823e-01, -1.9326e-01, -1.9237e-01,\n",
            "         -1.6582e-01, -1.1627e-01, -4.8450e-02,  3.1229e-02,  1.1531e-01],\n",
            "        [ 4.6099e-01,  4.6173e-01,  4.2897e-01,  3.6451e-01,  2.7279e-01,\n",
            "          1.6049e-01,  3.6083e-02, -9.0925e-02, -2.1070e-01, -3.1388e-01,\n",
            "         -3.9237e-01, -4.3994e-01, -4.5278e-01, -4.2981e-01, -3.7274e-01,\n",
            "         -2.8598e-01, -1.7625e-01, -5.2071e-02,  7.6940e-02,  2.0082e-01,\n",
            "          3.1010e-01,  3.9650e-01,  4.5365e-01,  4.7756e-01,  4.6694e-01,\n",
            "          4.2329e-01,  3.5076e-01,  2.5583e-01,  1.4674e-01,  3.2826e-02,\n",
            "         -7.6195e-02, -1.7104e-01, -2.4356e-01, -2.8740e-01, -2.9843e-01,\n",
            "         -2.7505e-01, -2.1824e-01, -1.3142e-01, -2.0042e-02,  1.0888e-01,\n",
            "          2.4752e-01,  3.8791e-01,  5.2275e-01,  6.4608e-01,  7.5389e-01,\n",
            "          8.4454e-01,  9.1898e-01,  9.8080e-01,  1.0360e+00,  1.0924e+00,\n",
            "          1.1594e+00,  1.2469e+00,  1.3646e+00,  1.5211e+00,  1.7231e+00,\n",
            "          1.9750e+00,  2.2778e+00,  2.6295e+00,  3.0243e+00,  3.4531e+00,\n",
            "          3.9041e+00,  4.3630e+00,  4.8137e+00,  5.2398e+00,  5.6247e+00,\n",
            "          5.9533e+00,  6.2123e+00,  6.3911e+00,  6.4828e+00,  6.4837e+00,\n",
            "          6.3944e+00,  6.2189e+00,  5.9651e+00,  5.6435e+00,  5.2670e+00,\n",
            "          4.8503e+00,  4.4085e+00,  3.9569e+00,  3.5096e+00,  3.0794e+00,\n",
            "          2.6768e+00,  2.3099e+00,  1.9839e+00,  1.7013e+00,  1.4619e+00,\n",
            "          1.2632e+00,  1.1007e+00,  9.6845e-01,  8.5981e-01,  7.6769e-01,\n",
            "          6.8534e-01,  6.0677e-01,  5.2713e-01,  4.4302e-01,  3.5262e-01,\n",
            "          2.5570e-01,  1.5355e-01,  4.8745e-02, -5.5161e-02, -1.5401e-01,\n",
            "         -2.4343e-01, -3.1926e-01, -3.7790e-01, -4.1667e-01, -4.3401e-01,\n",
            "         -4.2970e-01, -4.0483e-01, -3.6180e-01, -3.0415e-01, -2.3630e-01,\n",
            "         -1.6325e-01, -9.0222e-02, -2.2270e-02,  3.6072e-02,  8.1131e-02,\n",
            "          1.1037e-01,  1.2255e-01,  1.1787e-01,  9.7914e-02,  6.5539e-02,\n",
            "          2.4676e-02, -1.9983e-02, -6.3347e-02, -1.0032e-01, -1.2622e-01,\n",
            "         -1.3716e-01, -1.3038e-01, -1.0452e-01, -5.9749e-02,  2.1381e-03,\n",
            "          7.7844e-02,  1.6274e-01,  2.5115e-01,  3.3679e-01,  4.1313e-01,\n",
            "          4.7397e-01,  5.1385e-01,  5.2848e-01,  5.1514e-01,  4.7291e-01,\n",
            "          4.0281e-01,  3.0779e-01,  1.9260e-01,  6.3470e-02, -7.2229e-02,\n",
            "         -2.0651e-01, -3.3130e-01, -4.3899e-01, -5.2297e-01, -5.7810e-01,\n",
            "         -6.0108e-01, -5.9069e-01, -5.4786e-01, -4.7564e-01, -3.7895e-01,\n",
            "         -2.6422e-01, -1.3895e-01, -1.1128e-02,  1.1135e-01,  2.2126e-01]]), 'tof': tensor([1.0885])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgGG2h7qKElm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0bfc0f30-3ced-43d6-ea59-d809817e4bb1"
      },
      "source": [
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SzlAs8bLQCo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "74334d53-420b-4555-cf01-93b3dc77a204"
      },
      "source": [
        "########################################################################################\n",
        "## EXCUTION:Training ########\n",
        "########################################################################################\n",
        "\n",
        "\n",
        "trainWaveformDataset = Waveforms(fileName, train=True)\n",
        "testWaveformDataset = Waveforms(fileName, train=False)\n",
        "trainData = DataLoader(trainWaveformDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testData = DataLoader(testWaveformDataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "comNN = ComNN()\n",
        "comNN.cuda()\n",
        "print(comNN)\n",
        "\n",
        "optimizer = optim.Adam(comNN.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "# https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=LRD)\n",
        "print(optimizer)\n",
        "# loss_func = nn.MSELoss().cuda()\n",
        "loss_func = my_mse_loss\n",
        "\n",
        "testLoss_his = []\n",
        "trainLoss_his = []\n",
        "timeResolution_his = []\n",
        "mu_his = []\n",
        "residualTofList = []\n",
        "predictedTofList = []\n",
        "labelTofList = []\n",
        "\n",
        "print(\"Data: \" + DATA_VERSION + \"; SEED = \" + str(SEED)+\"； Epochs = \" + str(EPOCHS))\n",
        "progress = ProgressBar()\n",
        "for epoch in progress(range(EPOCHS)):\n",
        "    epoch_loss = 0  # for LR decay rate scheduler\n",
        "    for index, batch_data in enumerate(trainData):\n",
        "        input = Variable(batch_data['waveform']).cuda()\n",
        "        b_y = Variable(batch_data['tof']).cuda().squeeze()\n",
        "        # print(input.size())\n",
        "        output = comNN(input).squeeze()\n",
        "        loss = loss_func(output, b_y, 2)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.data.cpu().numpy()\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "    # to store the sigma, mu, loss\n",
        "    if (epoch) % SAMPLE_EPOCH == 0:\n",
        "        trainLoss_his.append(loss.data.cpu().numpy())\n",
        "        residualTofList.clear()\n",
        "        predictedTofList.clear()\n",
        "        labelTofList.clear()\n",
        "        for index, batch_data in enumerate(testData):\n",
        "            input = Variable(batch_data['waveform']).cuda()\n",
        "            b_y = Variable(batch_data['tof']).cuda().squeeze()\n",
        "            output = comNN(input).squeeze()\n",
        "            loss = loss_func(output, b_y, 2)\n",
        "            residualTofList.extend(\n",
        "                (output-b_y).cpu().detach().numpy().tolist())\n",
        "            predictedTofList.extend(output.cpu().detach().numpy().tolist())\n",
        "            labelTofList.extend(b_y.cpu().detach().numpy().tolist())\n",
        "            # print('output length: ',output.cpu().detach().numpy().tolist().__len__())\n",
        "        # print('toflist length: ',tofList.__len__())\n",
        "        (mu, sigma) = norm.fit(residualTofList)\n",
        "        timeResolution_his.append(sigma/math.sqrt(2))\n",
        "        mu_his.append(mu)\n",
        "        testLoss_his.append(loss.data.cpu().numpy())\n",
        "\n",
        "\n",
        "# save model\n",
        "torch.save(comNN, outputPath+outputPrefix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEvents =  7815.0\n",
            "NEvents =  7815.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ComNN(\n",
            "  (lstm): LSTM(160, 62, num_layers=4, bias=False, batch_first=True)\n",
            "  (out1): Linear(in_features=62, out_features=1, bias=False)\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0002997938539807655\n",
            "    weight_decay: 0.0007674443631751687\n",
            ")\n",
            "Data: Aug-200_900_6; SEED = 5； Epochs = 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (100 of 100) |######################| Elapsed Time: 0:00:45 Time:  0:00:45\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwrxZwKwLRKx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fd7f7328-3cfe-4211-8727-be18f3e371a9"
      },
      "source": [
        "########################################################################################\n",
        "## EXCUTION:Plotting ########\n",
        "########################################################################################\n",
        "time_start = time.time()\n",
        "plt.plot(testLoss_his, label='testLoss')\n",
        "plt.plot(trainLoss_his, label='trainLoss')\n",
        "plt.grid(True)\n",
        "# plt.ylim([0.01, 0.08])\n",
        "# plt.ylabel(\"MSE [ns^2]\")\n",
        "plt.title(\"Loss/MSE Vs Epochs\")\n",
        "plt.xlabel(\"sampled every \"+str(SAMPLE_EPOCH)+\" epochs\")\n",
        "plt.legend()\n",
        "plt.savefig(outputPath+outputPrefix+\"_Loss.png\")\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(mu_his)\n",
        "plt.grid(True)\n",
        "plt.title(\"Average predicted ToF Vs Epochs\")\n",
        "plt.ylabel(\"Average of predicted ToF [ns]\")\n",
        "plt.ylim([-0.1, 0.1])\n",
        "plt.xlabel(\"sampled every \"+str(SAMPLE_EPOCH)+\" epochs\")\n",
        "plt.savefig(outputPath+outputPrefix+\"_Mu.png\")\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(timeResolution_his)\n",
        "plt.ylabel(\"Time Resolution [ns]\")\n",
        "plt.grid(True)\n",
        "plt.ylim([0.05, 0.30])\n",
        "plt.title(\"TimeResolution Vs Epochs\")\n",
        "plt.xlabel(\"sampled every \"+str(SAMPLE_EPOCH)+\" epochs\")\n",
        "plt.savefig(outputPath+outputPrefix+\"_TR.png\")\n",
        "plt.clf()\n",
        "\n",
        "(mu, sigma) = norm.fit(residualTofList)\n",
        "n, bins, patches = plt.hist(residualTofList, 100, range=(-1, 1), density=1)\n",
        "# add a 'best fit' line\n",
        "y = norm.pdf(bins, mu, sigma)\n",
        "l = plt.plot(bins, y, 'r--', linewidth=2)\n",
        "plt.xlabel('Tof residual [ns]')\n",
        "# plt.ylabel('Probability')\n",
        "plt.title(r'$\\mathrm{Tof\\ residual:}\\ \\mu=%.3f ns,\\ \\sigma/\\sqrt{2}=%.3f ns$' %(mu, sigma/math.sqrt(2)))\n",
        "plt.grid(True)\n",
        "plt.savefig(outputPath+outputPrefix+\"_TofHist.png\")\n",
        "plt.clf()\n",
        "\n",
        "for dataVersion in ['300_6','345_6']:\n",
        "    testDataset(comNN, dataVersion, outputPrefix, input_prefix=workspace+\"/data/\")\n",
        "\n",
        "time_end = time.time()\n",
        "print('time cost', time_end-time_start, 's')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEvents =  4278.0\n",
            "Test Data: 300_6\n",
            "NEvents =  3538.0\n",
            "Test Data: 345_6\n",
            "time cost 3.7958462238311768 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvx8LAW10b2U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}